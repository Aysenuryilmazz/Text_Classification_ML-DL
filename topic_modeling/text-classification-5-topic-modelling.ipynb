{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom os import path\nfrom PIL import Image\nimport pickle\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom sklearn.decomposition import LatentDirichletAllocation as LDA\nfrom sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#load datasets\n\nwith open(\"../input/text-classification-2-feature-engineering/df_train.pkl\", 'rb') as data:\n    df_train = pickle.load(data)\n\nwith open(\"../input/text-classification-2-feature-engineering/df_test.pkl\", 'rb') as data:\n    df_test = pickle.load(data)\n    \nwith open(\"../input/text-classification-2-feature-engineering/le.pkl\", 'rb') as data:\n    le = pickle.load(data)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all=pd.concat([df_train, df_test])\ndf_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoder dict\nle_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nle_name_mapping","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word Cloud","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"text = \" \".join(review for review in df_all['review_parsed'])\n\nprint (\"There are {} words in the combination of all review.\".format(len(text)))\n\n# Create and generate a word cloud image:\nwordcloud = WordCloud(width=800, height=300,background_color=\"pink\").generate(text)\n\nplt.figure(figsize=(20,5))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_word_cloud(df, label, key):\n    \n    text = \" \".join(review for review in df[df['condition']==label]['review_parsed'].values)\n\n    print (\"There are {} words in the \".format(len(text)), key, \"condition\")\n\n    wordcloud = WordCloud(width=800, height=300,background_color=\"white\").generate(text)\n\n    plt.figure(figsize=(20,5))\n    plt.title(key, fontdict={'fontsize':20})\n    \n    # Display the generated image:\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key, value in le_name_mapping.items():\n    create_word_cloud(df_all, value, key)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Helper function(her bir küme(topic) içn top-5 sözcük bastırıyor)\ndef print_topics(model, count_vectorizer, n_top_words):\n    words = count_vectorizer.get_feature_names()\n    for topic_idx, topic in enumerate(model.components_):\n        print(\"\\nTopic #%d:\" % topic_idx)\n        print(\" \".join([words[i]\n                        for i in topic.argsort()[:-n_top_words - 1:-1]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer()\ncount_data = count_vectorizer.fit_transform(df_all['review_parsed'])\n\nnumber_topics = 10\nnumber_words = 8\n\nlda = LDA(n_components=number_topics, n_jobs=-1, random_state=8)\nlda.fit(count_data)\n\n# Print the topics found by the LDA model\nprint(\"Topics found via LDA:\")\nprint_topics(lda, count_vectorizer, number_words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# PCA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.manifold import TSNE\nimport gzip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load datasets\n\nwith gzip.open(\"../input/text-classification-3-2-text-representation/x_train_tfidf.pkl\", 'rb') as data:\n    x_train_tfidf = pickle.load(data)\n    \n\nwith gzip.open(\"../input/text-classification-3-2-text-representation/x_test_tfidf.pkl\", 'rb') as data:\n    x_test_tfidf = pickle.load(data)\n    \n\nwith gzip.open(\"../input/text-classification-3-2-text-representation/y_train.pkl\", 'rb') as data:\n    y_train = pickle.load(data)\n    \n\nwith gzip.open(\"../input/text-classification-3-2-text-representation/y_test.pkl\", 'rb') as data:\n    y_test = pickle.load(data)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\n\npca = PCA(n_components = 3)\npca_2 = PCA(n_components = 2)\ntitle = \"PCA decomposition\"  \n\n\nconcat_features_arr = np.concatenate([x_train_tfidf, x_test_tfidf], axis=0)\nconcat_labels_arr = np.concatenate([y_train, y_test], axis=0)\n\n# Fit and transform the features\npc = pca.fit_transform(concat_features_arr)\npc_2 = pca_2.fit_transform(concat_features_arr)\n\n# Put them into a dataframe\ndf_features = pd.DataFrame(data=pc,\n                 columns=['PC1', 'PC2', 'PC3'])\n\ndf_features_2 = pd.DataFrame(data=pc_2,\n                 columns=['PC1', 'PC2'])\n\n# Now we have to paste each row's label and its meaning\n# Convert labels array to df\ndf_labels = pd.DataFrame(data=concat_labels_arr,\n                         columns=['label'])\n\ndf_full = pd.concat([df_features, df_labels], axis=1)\ndf_full_2 = pd.concat([df_features_2, df_labels], axis=1)\n\nnew_dict = {value:key for key, value in le_name_mapping.items()}\n\n# And map labels\ndf_full['label_name'] = df_full['label']\ndf_full = df_full.replace({'label_name':new_dict})\n\ndf_full_2['label_name'] = df_full_2['label']\ndf_full_2 = df_full_2.replace({'label_name':new_dict})\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arr_full=df_full.to_numpy()\narr_full_2=df_full_2.to_numpy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter_3d(x=arr_full [:,0], y=arr_full [:,1], z=arr_full [:,2], color=arr_full [:,4])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(x=arr_full_2[:,0], y=arr_full_2[:,1], color=arr_full_2[:,3])\nfig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}