{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Feature Engineering\n\nIn this notebook, we'll follow these steps:\n- Text Cleansing and Preparation\n- Label Encoding\n- Train-test split","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pickle\nimport pandas as pd\nimport numpy as np\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#load the pickle file, (that is containing only top-15 conditions)\nwith open(\"../input/text-classification-1-eda/top_10_train.pickle\", 'rb') as data:\n    train_df = pickle.load(data)\n    \nwith open(\"../input/text-classification-1-eda/top_10_test.pickle\", 'rb') as data:\n    test_df = pickle.load(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([train_df, test_df]).reset_index(drop=True)\nprint(df_all.shape)\ndf_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#our new dataframe\ntrain_features=df_all.loc[: ,[\"condition\", \"review\", \"review_length\"]].reset_index(drop=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's see one sample review","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.loc[0]['review']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n# 1. Text cleaning and preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove special characters\n\ntrain_features['review_parsed_1'] = train_features['review'].str.replace(\"\\r\", \" \")\ntrain_features['review_parsed_1'] = train_features['review_parsed_1'].str.replace(\"\\n\", \" \")\ntrain_features['review_parsed_1'] = train_features['review_parsed_1'].str.replace(\"    \", \" \")\ntrain_features['review_parsed_1'] = train_features['review_parsed_1'].str.replace('\"', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove punctuation signs and numbers\n\npunk_num = string.punctuation + \"1234567890\"\ntrain_features['review_parsed_2'] = train_features['review_parsed_1']\n\nfor punct_sign in punk_num:\n    train_features['review_parsed_2'] = train_features['review_parsed_2'].str.replace(punct_sign, '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make all letters lowercase\n\ntrain_features['review_parsed_3'] = train_features['review_parsed_2'].str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove possessive pronouns\n\ntrain_features['review_parsed_4'] = train_features['review_parsed_3'].str.replace(\"'s\", \"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lemmatization downloading punkt and wordnet from NLTK\n\nnltk.download('punkt')\nprint(\"--------------------------\")\nnltk.download('wordnet')\n\n\n#create a lemmatizer object\nwordnet_lemmatizer = WordNetLemmatizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterate thru. every word with lemmatizer\n# https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/\n# https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\n\nlen_rows = len(train_features)\nlemmatized_text_list = []\n\nfor row in range(0, len_rows):\n    \n    # Create an empty list containing lemmatized words\n    lemmatized_list = []\n    \n    # Save the text and its words into an object\n    text = train_features.loc[row]['review_parsed_4']\n    text_words = text.split(\" \")\n\n    # Iterate through every word to lemmatize\n    for word in text_words:\n        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\")) #v=verb\n        \n    # Join the list\n    lemmatized_text = \" \".join(lemmatized_list)\n    \n    # Append to the list containing the texts\n    lemmatized_text_list.append(lemmatized_text)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features['review_parsed_5'] = lemmatized_text_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#stop words\nnltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove the stop words, (helping of a regular expression only detecting whole words)\nstop_words_list = list(stopwords.words('english'))\n#stop_words[:10]\n\ntrain_features['review_parsed_6'] = train_features['review_parsed_5']\n\nfor stop_word in stop_words_list:\n\n    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n    train_features['review_parsed_6'] = train_features['review_parsed_6'].str.replace(regex_stopword, '')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at some reviews and its modifications below.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.loc[5]['review']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.loc[5]['review_parsed_1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_features.loc[5]['review_parsed_2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_features.loc[5]['review_parsed_3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_features.loc[5]['review_parsed_4']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_features.loc[5]['review_parsed_5']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.loc[5]['review_parsed_6']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove unnecessary parsed columns from the dataframe \nlist_columns = [\"condition\", \"review\", \"review_parsed_6\", \"review_length\"]\ntrain_features = train_features[list_columns]\n\ntrain_features = train_features.rename(columns={'review_parsed_6': 'review_parsed'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Hand-made features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Word count in each review\ntrain_features['count_word']=train_features[\"review_parsed\"].apply(lambda x: len(str(x).split()))\n\n#Unique word count \ntrain_features['count_unique_word']=train_features[\"review_parsed\"].apply(lambda x: len(set(str(x).split())))\n\n#Letter count\ntrain_features['count_letters']=train_features[\"review_parsed\"].apply(lambda x: len(str(x)))\n\n#punctuation count\ntrain_features[\"count_punctuations\"] = train_features[\"review\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n\n#upper case words count\ntrain_features[\"count_words_upper\"] = train_features[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n\n#title case words count\ntrain_features[\"count_words_title\"] = train_features[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n\n#numbers count\ntrain_features[\"count_numbers\"] = train_features[\"review\"].apply(lambda x: len([w for w in str(x).split() if w.isnumeric()]))\n\n#Number of stopwords\ntrain_features[\"count_stopwords\"] = train_features[\"review\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words_list]))\n\n#Average length of the words\ntrain_features[\"mean_word_len\"] = train_features[\"review_parsed\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_features\nwith open('train_features.pkl', 'wb') as output:\n    pickle.dump(train_features, output)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation Heatmap of the features\n\ntrain_corr = train_features.corr()\n\n# correlation matrix\nsns.set(font_scale=1)\nplt.figure(figsize=(14,10))\nsns.heatmap(train_corr, annot=True, fmt=\".4f\",vmin=-1, vmax=1, linewidths=.5, cmap = sns.color_palette(\"BrBG\", 100))\n#plt.yticks(rotation=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you can see the correlations bet. hand-made fetaures and target label are close to zero. So, they won't have significant effect on our predictions. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#average words count&condition relationship\n\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(10, 5))\nax = sns.barplot(x=\"condition\", y=\"count_word\", data=train_features, palette=sns.light_palette((210, 90, 60), input=\"husl\"))\nplt.xticks(rotation=90)\nplt.title(\"condition vs words count\", {\"fontname\":\"fantasy\", \"fontweight\":\"bold\", \"fontsize\":\"medium\"})\nplt.ylabel(\"words count\", {\"fontname\": \"serif\", \"fontweight\":\"bold\"})\nplt.xlabel(\"condition\", {\"fontname\": \"serif\", \"fontweight\":\"bold\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#average titles(possible drug names) count&condition relationship\n\nsns.set(style=\"whitegrid\")\nplt.figure(figsize=(10, 5))\nax = sns.barplot(x=\"condition\", y=\"count_words_title\", data=train_features, palette=sns.light_palette(\"navy\", reverse=True))\nplt.xticks(rotation=90)\nplt.title(\"condition vs titles count\", {\"fontname\":\"fantasy\", \"fontweight\":\"bold\", \"fontsize\":\"medium\"})\nplt.ylabel(\"titles count\", {\"fontname\": \"serif\", \"fontweight\":\"bold\"})\nplt.xlabel(\"condition\", {\"fontname\": \"serif\", \"fontweight\":\"bold\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Label Encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#encode \"condition\" col\n\nle = LabelEncoder()\narr=le.fit_transform(train_features['condition'])\n\ntrain_features['condition']=arr\n\n#get pickle for le object to use \"text classification\" notebook\nwith open('le.pkl', 'wb') as output:\n    pickle.dump(le, output) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Train-test split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train, df_test = train_test_split(train_features, test_size=0.25, random_state=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get pickles for train&test will be used for text representation in the next step   \nwith open('df_train.pkl', 'wb') as output:\n    pickle.dump(df_train, output)\n    \nwith open('df_test.pkl', 'wb') as output:\n    pickle.dump(df_test, output) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}